{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define randomness (SEED) and your  X_train, y_train, X_val, y_val, X_test, y_test \n",
        "# SEED = 42\n",
        "# X_train, y_train, X_val, y_val, X_test, y_test\n",
      ],
      "metadata": {
        "id": "aE5LA1zeNQWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(units_tuple, learning_rate, dropout_rate_1, dropout_rate_2, dropout_rate_3, l2_reg):\n",
        "    reg = regularizers.L2(l2_reg) if l2_reg and l2_reg > 0 else None\n",
        "    model = Sequential([\n",
        "        Dense(units_tuple[0], activation='relu', kernel_regularizer=reg, input_shape=(X_train.shape[1],)),\n",
        "        Dropout(dropout_rate_1),\n",
        "        Dense(units_tuple[1], activation='relu', kernel_regularizer=reg),\n",
        "        Dropout(dropout_rate_2),\n",
        "        Dense(units_tuple[2], activation='relu', kernel_regularizer=reg),\n",
        "        Dropout(dropout_rate_3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "y-cNHKtwFOzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_params = {\n",
        "    \"units\": [(64, 32, 4),],\n",
        "    \"learning_rate\": [1e-3, 2e-3],\n",
        "    \"batch_size\": [8, 16, 32],\n",
        "    \"epochs\": [150],\n",
        "    \"patience\": [10],\n",
        "    \"dropout_rate_1\": [0.0, 0.05, 0.1, 0.2],\n",
        "    \"dropout_rate_2\": [0.0, 0.05, 0.1, 0.2],\n",
        "    \"dropout_rate_3\": [0.0, 0.05, 0.1, 0.2],\n",
        "    \"l2_reg\": [0.0, 1e-4, 1e-3]\n",
        "\n",
        "}\n",
        "\n",
        "results = []\n",
        "best_val_acc = -1.0\n",
        "best_config = None\n",
        "best_model = None\n",
        "\n",
        "for units in grid_params[\"units\"]:\n",
        "    for lr in grid_params[\"learning_rate\"]:\n",
        "        for batch_size in grid_params[\"batch_size\"]:\n",
        "            for epochs in grid_params[\"epochs\"]:\n",
        "                for patience in grid_params[\"patience\"]:\n",
        "                    for dropout_rate1 in grid_params[\"dropout_rate_1\"]:\n",
        "                      for dropout_rate2 in grid_params[\"dropout_rate_2\"]:\n",
        "                        for dropout_rate3 in grid_params[\"dropout_rate_3\"]:\n",
        "                          for l2_reg in grid_params[\"l2_reg\"]:\n",
        "                                tf.keras.backend.clear_session()\n",
        "                                tf.random.set_seed(SEED)\n",
        "                                np.random.seed(SEED)\n",
        "                                random.seed(SEED)\n",
        "\n",
        "                                model = build_model(units, lr, dropout_rate1, dropout_rate2, dropout_rate3, l2_reg)\n",
        "\n",
        "                                early_stop = EarlyStopping(\n",
        "                                    monitor='val_loss',\n",
        "                                    patience=patience,\n",
        "                                    restore_best_weights=True,\n",
        "                                    verbose=0\n",
        "                                )\n",
        "\n",
        "                                history = model.fit(\n",
        "                                    X_train, y_train,\n",
        "                                    epochs=epochs,\n",
        "                                    batch_size=batch_size,\n",
        "                                    validation_data=(X_val, y_val),\n",
        "                                    callbacks=[early_stop],\n",
        "                                    verbose=0\n",
        "                                )\n",
        "\n",
        "                                val_acc = history.history['val_accuracy'][-1]\n",
        "                                val_loss = history.history['val_loss'][-1]\n",
        "                                trained_epochs = len(history.history['loss'])\n",
        "\n",
        "                                results.append({\n",
        "                                    \"units\": units,\n",
        "                                    \"learning_rate\": lr,\n",
        "                                    \"batch_size\": batch_size,\n",
        "                                    \"epochs\": epochs,\n",
        "                                    \"patience\": patience,\n",
        "                                    \"dropout_rate_1\": dropout_rate1,\n",
        "                                    \"dropout_rate_2\": dropout_rate2,\n",
        "                                    \"dropout_rate_3\": dropout_rate3,\n",
        "                                    \"trained_epochs\": trained_epochs,\n",
        "                                    \"val_accuracy\": val_acc,\n",
        "                                    \"val_loss\": val_loss,\n",
        "                                    \"model\": model,\n",
        "                                    \"history\": history\n",
        "                                })\n",
        "\n",
        "                                print(f\"units={units}, lr={lr}, batch_size={batch_size}, dropout_1={dropout_rate1},dropout_2={dropout_rate2},dropout_3={dropout_rate3}, \"\n",
        "                                      f\"l2={l2_reg}, patience={patience} -> trained_epochs={trained_epochs}, \"\n",
        "                                      f\"val_acc={val_acc:.4f}, val_loss={val_loss:.4f}\")\n",
        "\n",
        "                                if val_acc > best_val_acc:\n",
        "                                    best_val_acc = val_acc\n",
        "                                    best_config = {\n",
        "                                        \"units\": units,\n",
        "                                        \"learning_rate\": lr,\n",
        "                                        \"batch_size\": batch_size,\n",
        "                                        \"epochs\": epochs,\n",
        "                                        \"patience\": patience,\n",
        "                                        \"dropout_rate_1\": dropout_rate1,\n",
        "                                        \"dropout_rate_2\": dropout_rate2,\n",
        "                                        \"dropout_rate_3\": dropout_rate3,\n",
        "                                        \"l2_reg\": l2_reg\n",
        "\n",
        "                                    }\n",
        "                                    best_model = model\n",
        "                                    best_history = history\n",
        "\n",
        "# Final report\n",
        "print(\"\\nBest validation accuracy:\", best_val_acc)\n",
        "print(\"Best hyperparameters:\", best_config)\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test set performance -> loss: {test_loss:.4f}, accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "j7af_hqnry4k",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tf2w8d5hWB8n"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
